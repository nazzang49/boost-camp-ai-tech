{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention\n",
    "- Reference\n",
    "    - https://ratsgo.github.io/nlpbook/docs/language_model/tr_self_attention/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-09T12:12:17.506178Z",
     "start_time": "2021-08-09T12:12:12.789787Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "    input_x: sequential input data\n",
    "    w_key: weights for making key matrix\n",
    "    w_query: weights for making query matrix\n",
    "    w_value: weights for making value matrix\n",
    "'''\n",
    "\n",
    "x = torch.tensor([\n",
    "  [1.0, 0.0, 1.0, 0.0],\n",
    "  [0.0, 2.0, 0.0, 2.0],\n",
    "  [1.0, 1.0, 1.0, 1.0],  \n",
    "])\n",
    "w_key = torch.tensor([\n",
    "  [0.0, 0.0, 1.0],\n",
    "  [1.0, 1.0, 0.0],\n",
    "  [0.0, 1.0, 0.0],\n",
    "  [1.0, 1.0, 0.0]\n",
    "])\n",
    "w_query = torch.tensor([\n",
    "  [1.0, 0.0, 1.0],\n",
    "  [1.0, 0.0, 0.0],\n",
    "  [0.0, 0.0, 1.0],\n",
    "  [0.0, 1.0, 1.0]\n",
    "])\n",
    "w_value = torch.tensor([\n",
    "  [0.0, 2.0, 0.0],\n",
    "  [0.0, 3.0, 0.0],\n",
    "  [1.0, 0.0, 3.0],\n",
    "  [1.0, 1.0, 0.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-09T12:16:33.261204Z",
     "start_time": "2021-08-09T12:16:33.250515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1.]\n",
      " [4. 4. 0.]\n",
      " [2. 3. 1.]]\n",
      "[[1. 0. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 1. 3.]]\n",
      "[[1. 2. 3.]\n",
      " [2. 8. 0.]\n",
      " [2. 6. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# get ready\n",
    "keys = np.dot(x, w_key)\n",
    "querys = np.dot(x, w_query)\n",
    "values = np.dot(x, w_value)\n",
    "\n",
    "# 3 x 3\n",
    "print(keys)\n",
    "print(querys)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-09T12:17:40.806605Z",
     "start_time": "2021-08-09T12:17:40.787014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  4.  4.]\n",
      " [ 4. 16. 12.]\n",
      " [ 4. 12. 10.]]\n"
     ]
    }
   ],
   "source": [
    "# attention score\n",
    "attention_score = np.dot(querys, keys.T)\n",
    "print(attention_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-09T12:28:29.053122Z",
     "start_time": "2021-08-09T12:28:29.028040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3613e-01, 4.3194e-01, 4.3194e-01],\n",
      "        [8.9045e-04, 9.0884e-01, 9.0267e-02],\n",
      "        [7.4449e-03, 7.5471e-01, 2.3785e-01]])\n"
     ]
    }
   ],
   "source": [
    "# softmax\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# keys.shape[-1] = length of sequence\n",
    "attention_score_softmax = softmax(torch.Tensor(attention_score) / np.sqrt(keys.shape[1]), dim=-1)\n",
    "print(attention_score_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-09T12:31:00.463501Z",
     "start_time": "2021-08-09T12:31:00.426504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 7.0000, 1.5000],\n",
       "        [2.0000, 8.0000, 0.0000],\n",
       "        [2.0000, 7.8000, 0.3000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weighted sum\n",
    "\n",
    "# exmaple\n",
    "attn_scores_softmax = torch.tensor([\n",
    "  [0.0, 0.5, 0.5],\n",
    "  [0.0, 1.0, 0.0],\n",
    "  [0.0, 0.9, 0.1]\n",
    "])\n",
    "\n",
    "weighted_values = attn_scores_softmax @ values\n",
    "weighted_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
