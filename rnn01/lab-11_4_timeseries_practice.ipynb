{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Predict Stock of the day 8 through Timeseries data of previous 1-week by PyTorch\\n'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Predict Stock of the day 8 through Timeseries data of previous 1-week by PyTorch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f80c515c8b8>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameter\n",
    "seq_length = 7 # 1-week\n",
    "data_dim = 5   # open price / high price / low price / volume / close price\n",
    "hidden_dim = 10# output_size of RNN model\n",
    "output_dim = 1 # after FCL = final prediction\n",
    "learning_rate = 0.01\n",
    "iterations = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(732, 5)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "xy = np.loadtxt('data-02-stock_daily.csv', delimiter=',')\n",
    "xy = xy[::-1] # reverse order\n",
    "print(xy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "train_size = int(len(xy) * 0.8) # 732 * 0.8 => 578\n",
    "\n",
    "train_set = xy[0: train_size]\n",
    "test_set = xy[train_size - seq_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (real value - min value) / (max value - min value) => >=0 and < 1\n",
    "def minmax_scaler(data):\n",
    "    numerator = data - np.min(data, 0) # axis=0 => 5 feature\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(time_series, seq_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(time_series) - seq_length):\n",
    "        _x = time_series[i:i + seq_length, :]   # 1set = 1-week informations (5 feature)\n",
    "        _y = time_series[i + seq_length, [-1]]  # target = next close price right after 1-week\n",
    "#         print(_x, \"->\", _y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling => price = approx 800 / transaction = approx 100000000 => too much diff of range => 0 ~ 1 scaling\n",
    "train_set = minmax_scaler(train_set)\n",
    "test_set = minmax_scaler(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578, 7, 5)\n"
     ]
    }
   ],
   "source": [
    "# split X and Y by numpy\n",
    "trainX, trainY = build_dataset(train_set, seq_length)\n",
    "testX, testY = build_dataset(test_set, seq_length)\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.5307e-01, 2.4507e-01, 2.3398e-01, 4.6608e-04, 2.3204e-01],\n",
       "         [2.2960e-01, 2.3973e-01, 2.5457e-01, 2.9847e-03, 2.3743e-01],\n",
       "         [2.4924e-01, 2.4167e-01, 2.4834e-01, 2.5993e-04, 2.2679e-01],\n",
       "         ...,\n",
       "         [3.6343e-01, 3.7039e-01, 2.6717e-01, 1.2476e-02, 2.6211e-01],\n",
       "         [2.5945e-01, 3.1067e-01, 2.7411e-01, 4.5632e-01, 2.7175e-01],\n",
       "         [2.7601e-01, 2.7831e-01, 1.9847e-01, 5.7017e-01, 1.7810e-01]],\n",
       "\n",
       "        [[2.2960e-01, 2.3973e-01, 2.5457e-01, 2.9847e-03, 2.3743e-01],\n",
       "         [2.4924e-01, 2.4167e-01, 2.4834e-01, 2.5993e-04, 2.2679e-01],\n",
       "         [2.2101e-01, 2.4660e-01, 2.5471e-01, 0.0000e+00, 2.6267e-01],\n",
       "         ...,\n",
       "         [2.5945e-01, 3.1067e-01, 2.7411e-01, 4.5632e-01, 2.7175e-01],\n",
       "         [2.7601e-01, 2.7831e-01, 1.9847e-01, 5.7017e-01, 1.7810e-01],\n",
       "         [1.5902e-01, 1.7865e-01, 1.4173e-01, 3.9381e-01, 1.6054e-01]],\n",
       "\n",
       "        [[2.4924e-01, 2.4167e-01, 2.4834e-01, 2.5993e-04, 2.2679e-01],\n",
       "         [2.2101e-01, 2.4660e-01, 2.5471e-01, 0.0000e+00, 2.6267e-01],\n",
       "         [3.6343e-01, 3.7039e-01, 2.6717e-01, 1.2476e-02, 2.6211e-01],\n",
       "         ...,\n",
       "         [2.7601e-01, 2.7831e-01, 1.9847e-01, 5.7017e-01, 1.7810e-01],\n",
       "         [1.5902e-01, 1.7865e-01, 1.4173e-01, 3.9381e-01, 1.6054e-01],\n",
       "         [1.6543e-01, 2.0084e-01, 1.9349e-01, 2.8173e-01, 2.1951e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[7.0674e-01, 7.1364e-01, 7.4774e-01, 1.4048e-01, 7.5015e-01],\n",
       "         [7.3624e-01, 7.5038e-01, 7.8642e-01, 9.8942e-02, 7.8345e-01],\n",
       "         [7.7443e-01, 7.7226e-01, 8.1746e-01, 1.1912e-01, 8.0299e-01],\n",
       "         ...,\n",
       "         [7.8292e-01, 7.6978e-01, 8.2505e-01, 8.4458e-02, 8.0408e-01],\n",
       "         [7.9724e-01, 7.8179e-01, 8.2872e-01, 1.1396e-01, 8.0021e-01],\n",
       "         [7.8682e-01, 8.1714e-01, 8.3636e-01, 1.1541e-01, 8.4925e-01]],\n",
       "\n",
       "        [[7.3624e-01, 7.5038e-01, 7.8642e-01, 9.8942e-02, 7.8345e-01],\n",
       "         [7.7443e-01, 7.7226e-01, 8.1746e-01, 1.1912e-01, 8.0299e-01],\n",
       "         [7.8996e-01, 7.7587e-01, 8.2083e-01, 8.3176e-02, 7.9011e-01],\n",
       "         ...,\n",
       "         [7.9724e-01, 7.8179e-01, 8.2872e-01, 1.1396e-01, 8.0021e-01],\n",
       "         [7.8682e-01, 8.1714e-01, 8.3636e-01, 1.1541e-01, 8.4925e-01],\n",
       "         [8.1159e-01, 8.2007e-01, 8.6432e-01, 1.0931e-01, 8.6045e-01]],\n",
       "\n",
       "        [[7.7443e-01, 7.7226e-01, 8.1746e-01, 1.1912e-01, 8.0299e-01],\n",
       "         [7.8996e-01, 7.7587e-01, 8.2083e-01, 8.3176e-02, 7.9011e-01],\n",
       "         [7.8292e-01, 7.6978e-01, 8.2505e-01, 8.4458e-02, 8.0408e-01],\n",
       "         ...,\n",
       "         [7.8682e-01, 8.1714e-01, 8.3636e-01, 1.1541e-01, 8.4925e-01],\n",
       "         [8.1159e-01, 8.2007e-01, 8.6432e-01, 1.0931e-01, 8.6045e-01],\n",
       "         [8.3726e-01, 8.3756e-01, 8.9332e-01, 1.1489e-01, 8.7534e-01]]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy to tensor\n",
    "trainX_tensor, trainY_tensor = torch.FloatTensor(trainX), torch.FloatTensor(trainY)\n",
    "testX_tensor, testY_tensor = torch.FloatTensor(testX), torch.FloatTensor(testY)\n",
    "\n",
    "trainX_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # LSTM\n",
    "        self.rnn = torch.nn.LSTM(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
    "        \n",
    "        # hidden_dim => output_dim\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x => (578, 7, 5) / 7 = seq_length / 5 = input_dim\n",
    "        print('x의 형태 before rnn: ', x.shape)\n",
    "        x, _status = self.rnn(x)\n",
    "        tmp = x[:, -1]\n",
    "        \n",
    "        # x => (578, 7, 10)\n",
    "        print('x[0]의 형태: ', x[0].shape)\n",
    "        print('x[0]의 값: ', x[0])\n",
    "        print('tmp의 형태: ', tmp.shape)\n",
    "        print('tmp의 값: ', tmp)\n",
    "        \n",
    "        x = self.fc(x[:, -1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 => stacking size\n",
    "net = Net(data_dim, hidden_dim, output_dim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = torch.nn.MSELoss() # final output => float value\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 형태 before rnn:  torch.Size([578, 7, 5])\n",
      "x[0]의 형태:  torch.Size([7, 10])\n",
      "x[0]의 값:  tensor([[-0.0331,  0.0301,  0.0660, -0.1667, -0.0310, -0.0230,  0.0531,  0.0503,\n",
      "         -0.0475,  0.0458],\n",
      "        [-0.0587,  0.0481,  0.1036, -0.2305, -0.0600, -0.0336,  0.0882,  0.0864,\n",
      "         -0.0750,  0.0727],\n",
      "        [-0.0727,  0.0594,  0.1231, -0.2565, -0.0766, -0.0363,  0.1088,  0.1095,\n",
      "         -0.0892,  0.0867],\n",
      "        [-0.0846,  0.0659,  0.1347, -0.2663, -0.0891, -0.0361,  0.1230,  0.1263,\n",
      "         -0.0973,  0.0936],\n",
      "        [-0.0787,  0.0613,  0.1402, -0.2764, -0.0922, -0.0473,  0.1304,  0.1340,\n",
      "         -0.0939,  0.0943],\n",
      "        [-0.0924,  0.0595,  0.1554, -0.2584, -0.0887, -0.0622,  0.1293,  0.1397,\n",
      "         -0.0944,  0.0763],\n",
      "        [-0.0930,  0.0635,  0.1730, -0.2482, -0.0697, -0.0646,  0.1223,  0.1430,\n",
      "         -0.0972,  0.0642]], grad_fn=<SelectBackward>)\n",
      "tmp의 형태:  torch.Size([578, 10])\n",
      "tmp의 값:  tensor([[-0.0930,  0.0635,  0.1730,  ...,  0.1430, -0.0972,  0.0642],\n",
      "        [-0.0974,  0.0749,  0.1858,  ...,  0.1480, -0.1053,  0.0677],\n",
      "        [-0.1008,  0.0762,  0.1849,  ...,  0.1521, -0.1085,  0.0716],\n",
      "        ...,\n",
      "        [-0.0840, -0.0100,  0.1418,  ...,  0.1758, -0.0146,  0.0334],\n",
      "        [-0.0842, -0.0118,  0.1413,  ...,  0.1767, -0.0127,  0.0314],\n",
      "        [-0.0840, -0.0146,  0.1399,  ...,  0.1770, -0.0094,  0.0291]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "1 번째 Loss:  0.28214702010154724\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for i in range(iterations):\n",
    "    outputs = net(trainX_tensor)\n",
    "    loss = criterion(outputs, trainY_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print((i+1), '번째 Loss: ', loss.item())\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
